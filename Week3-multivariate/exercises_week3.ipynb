{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# week 3, session 1\n",
    "\n",
    "# Multivariate normal distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker, colors\n",
    "from scipy.stats import norm\n",
    "from scipy import special\n",
    "from scipy.stats import multivariate_normal\n",
    "from ipywidgets import interact,FloatSlider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Independent univariate normal distributions\n",
    "\n",
    "A one-dimensional normal distribution, is parameterized by its mean, $\\mu$, and variance, $\\sigma^2$. The mean describes the location of the variable, while the variance describes the scale of the variable as the variation around the mean. The probability density function is\n",
    "\n",
    "$$ \n",
    "\\mathcal{N}(x;\\mu,\\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2} }   \\text{exp}\\left( -\\frac{(x - \\mu)^2}{2\\sigma^2} \\right)\n",
    "$$ \n",
    "In a two dimensional random process, samples are defined by two values, $x = (x_1,x_2)$. In this exercise, we imagine that the density for each component is an independent normal distribution, such that \n",
    "$x_1\\sim\\mathcal{N}(\\mu_1,\\sigma^2_1)$ and $x_2\\sim\\mathcal{N}(\\mu_2,\\sigma^2_2)$.  \n",
    "\n",
    "In the following questions, let $\\mu_1 = 5, \\mu_2 = 20, \\sigma^2_1 = 2, \\sigma^2_2 = 5$\n",
    "\n",
    "### Questions\n",
    "$\\star$ Generate a dataset by sampling $N = 10000$ samples from the random process, such that each sample is defined by two values $x_1$ and $x_2$. \n",
    "\n",
    "$\\star$ Visualize the sampled data in a 2-dimensional scatter plot.\n",
    "\n",
    "$\\star$ Use np.mean and np.var to compute the sample-means and sample-variances. Compare with $\\mu_1, \\mu_2$ and $\\sigma^2_1, \\sigma^2_2$. Comment on the result for different number of samples $N$.\n",
    "\n",
    "$\\star$ For each dimension; plot a normalized histogram of the sample-values together with the density function given by the corresponding normal distribution.  Comment on the results when varying the number of samples $N$.\n",
    "\n",
    "$\\star$ For a random sample $(x_1,x_2)$, what is the probability $\\mathbb{P}(x_1\\leq \\mu1 \\cap x_2\\leq \\mu2)$. How could you investigate this empirically?\n",
    "\n",
    "\n",
    "### Hints\n",
    "\n",
    "$\\bullet$ Remember that in Numpy, the normal distribution is defined by the location (by the mean) and scale (by the standard deviation - not the variance). \n",
    "\n",
    "$\\bullet$ You can use the command plt.axis('equal') to force a plot to have equal axis ratios. This might make the scatterplot easier to read.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate normal distribution\n",
    "\n",
    "\n",
    "In $d$ dimensions, the multivariate normal probability density function is given by\n",
    "\n",
    "$$\n",
    "\\mathcal{N}(\\mathbf{x}; \\mathbf{\\mu},\\mathbf{\\Sigma}) = \\frac{1}{ \\sqrt{ (2\\pi)^d |\\mathbf{\\Sigma}|}}\\exp\\left( -\\frac{1}{2}(\\mathbf{x}-\\mathbf{\\mu})^T\\mathbf{\\Sigma}^{-1}(\\mathbf{x}-\\mathbf{\\mu}) \\right)\n",
    "$$\n",
    "where $\\mathbf{\\mu}$ is a $d$-dimensional vector and $\\mathbf{\\Sigma}$ is the $d\\times d$ covariance matrix.\n",
    "\n",
    "We still consider sampling in two dimensions, such that a sample is given by two values $x = (x_1,x_2)$, with $(\\mu_1,\\mu_2)$ representing the means and $(\\sigma^2_1,\\sigma^2_2)$ representing the variance in the respective dimensions.\n",
    "\n",
    "Now consider the case where the two components are correlated, such that there is a trend that whenever $x_1$ is larger than $\\mu_1$, then $x_2$ tends to also be larger than $\\mu_2$. And whenever $x_1$ is smaller than $\\mu_1$ then $x_2$ tends to be smaller than $\\mu_2$.  \n",
    "\n",
    "In this case we cannot sample from two independent normal distributions, as they cannot describe the covariance between components. Instead, let $\\mathbf{x}$ be a 2-dimensional (multivariate) normal distribution given by a mean, $\\mathbf{\\mu} = (\\mu_1, \\mu_2)$ and covariance matrix $\\mathbf{\\Sigma}$.\n",
    "\n",
    "\n",
    "The covariance between components can be computed as, $\\text{cov}[x_1,x_2] \\equiv \\mathbb{E}[(x_1 - \\mu_1)(x_2-\\mu_2)]$. The covariance matrix is then given by\n",
    "\n",
    "$$\\mathbf{\\Sigma} = \\begin{bmatrix}\\sigma^2_{1} & \\text{cov}[x_1,x_2]\\\\ \\text{cov}[x_2,x_1] &\\sigma^2_{2}\\end{bmatrix}\n",
    "= \\begin{bmatrix}\\sigma_{11} &\\sigma_{12}\\\\ \\sigma_{21} &\\sigma_{22}\\end{bmatrix}.$$\n",
    "\n",
    "The terms $\\sigma_{21}$ and $\\sigma_{12}$ must be equal as they describe the covariance between the same components. The covariance matrix is hence always symmetric.\n",
    "\n",
    "In this exercise, let $\\mu_1,\\mu_2,\\sigma^2_1,\\sigma^2_2$ be the same values as in the previous exercise, and set the covariance to $\\sigma_{12} = \\sigma_{21} = 2.5$.\n",
    "\n",
    "### Questions\n",
    "\n",
    "$\\star$ Convince yourself that the sampled data from the previous exercise is independent, by computing the empirical covariance between the two components. \n",
    "\n",
    "$\\star$ Generate a dataset with $N = 10000$ samples from the 2-dimensional normal $X\\sim\\mathcal{N}(\\mathbf{\\mu},\\Sigma)$. \n",
    "\n",
    "$\\star$ Use np.mean and np.cov to compute the sample mean and sample covariance matrix for the data. Compare with $\\mathbf{\\mu}$ and $\\Sigma$ and comment on the results when varying $N$.\n",
    "\n",
    "\n",
    "$\\star$ Create a function that shows the following plots when provided with a dataset, and the $\\mathbf{\\mu}$ and $\\mathbf{\\Sigma}$ variables for the 2D normal from which the data was sampled.\n",
    "-  The sampled data as a scatter plot. \n",
    "-  A countour plot for the 2D normal, such as:\n",
    "        \n",
    "        x, y = np.meshgrid(np.linspace(0,10,100),np.linspace(10,30,200))\n",
    "        pos = np.empty(x.shape + (2,))\n",
    "        pos[:, :, 0] = x; pos[:, :, 1] = y\n",
    "        multinorm = multivariate_normal([mu1, mu2], [[sigma11, sigma12], [sigma21, sigma22]])\n",
    "        plt.contour(x, y, multinorm.pdf(pos))\n",
    "        plt.grid(True)\n",
    "        plt.axis('equal')\n",
    "\n",
    "- In a separate figure for each of the two components, plot the normalized histogram for the data. Add the plot of the corresponding marginal probability densitity functions, $p(x_1)$ and $p(x_2)$, to these figures.\n",
    "\n",
    "\n",
    "\n",
    "$\\star$ Use the plotting function to visualize the generated data. Comment on the figures in comparison with the results obtained from previously sampling independently in the previous exercise.\n",
    "\n",
    "### Hints\n",
    "\n",
    "$\\bullet$ You can draw from the multivariate normal distribution using the numpy function np.random.multivariate_normal\n",
    "\n",
    "$\\bullet$ To make the figures easier to compare, you can plot them side-by-side using the plt.subplot features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Interpretation of the covariance\n",
    "\n",
    "The correlation coefficient, $\\rho$, is a quantity for describing the correlation between components. It is defined as the normalized covariance, as\n",
    "$$ \\rho = \\dfrac{\\text{cov}[x_1,x_2]}{\\sqrt{\\sigma^2_1\\sigma^2_2}}  = \\dfrac{\\sigma_{12}}{\\sqrt{\\sigma_{12}\\sigma_{21}}}\\quad,\\qquad \\text{where $\\rho\\in[-1,1]$} $$\n",
    "\n",
    "### Questions\n",
    "\n",
    "$\\star$ Use the plotting function to create similar visualizations for the 2-dimensional normal distribution but with different covariance matrices.\n",
    "- For example, try to fix the variances, $\\sigma^2_1$ and $\\sigma^2_2$, while only changing the covariance. \n",
    "- Comment on how the orientation and shape of the ellipsoids (in the contour plots) depends on the covariance matrix. \n",
    "- Can you create a situation where $\\rho = 1$ or $\\rho = -1$. Comment on the relationship between $x_1$ and $x_2$ as $\\rho$ approaches  $1$ or $-1$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marginals and conditionals of the 2D normal\n",
    "\n",
    "A very convenient property of the 2-dimensional normal distribution is that, when one of the variables $y$ is fixed at a known value $v$,  the conditional probability density function for the other variable $p(x|y=v)$ follows a normal distribution  $p(x|y=v)\\sim\\mathcal{N}$ $(\\mu_{x|y=v}\\;,\\;\\sigma^2_{x|y=v})$.\n",
    "\n",
    "Here, the conditional mean and variance of $x$ is given by:\n",
    "\n",
    "$$ \\mu_{x|y=v} = \\mu_{x} + \\rho \\sigma_x \\dfrac{v - \\mu_y}{\\sigma_y}  $$\n",
    "\n",
    "$$ \\sigma_{x|y=v} = \\sigma_x \\sqrt{1-\\rho^2} $$\n",
    "\n",
    "\n",
    "The two dimensional normal with $\\mathbf{\\mu} = 0$ and $\\mathbf\\Sigma = \\begin{bmatrix} 1 & \\rho \\\\ \\rho & 1 \\end{bmatrix}$ is known as the standard bivariate normal distribution with correlation coefficient $\\rho$. The probability density function is then\n",
    "\n",
    "$$ p(x_1,x_2) = \\dfrac{1}{2\\pi\\sqrt{1-\\rho^2}} \\exp \\left( -\\frac{ 1 }{ 2(1-\\rho^2)}(x_1^2 + x_2^2 - 2\\rho x_1 x_2)   \\right)  $$\n",
    "\n",
    "\n",
    "### Questions\n",
    "\n",
    "\n",
    "$\\star$ This exercise will demonstrate how you can derive the marginals and conditionlas of the density;\n",
    "- Complete the square (see hint) in the expression:\n",
    "$$ x_1^2 + x_2^2 - 2\\rho x_1 x_2 + \\underbrace{((\\rho x_1)^2-(\\rho x_1)^2)}_{0} $$\n",
    "- Show mathematically that the joint is equal to $p(x_2|x_1)p(x_1)$ using,\n",
    "$$ p(x_2 | x_1) = \\mathcal{N}(x_2; \\rho x_1, 1-\\rho^2),\\quad p(x_1) = \\mathcal{N}(x_1;0,1).  $$\n",
    "- What happens as $\\rho$ gets close to $-1$ or $1$? \n",
    "- For what value of $\\rho$ is $p(x_2|x_1)=p(x_1)$, making $X_1$ and $X_2$ independent?\n",
    "\n",
    "$\\star$ The following widget allows you to interactively change the covariance and fixed value of $y$ for a standard bivariate normal distribution $p(x,y)$. \n",
    "- Comment on the relation between $p(x)$ and $p(x|y=v)$ for different $v$ and $\\rho$ configurations.\n",
    "\n",
    "### Hints\n",
    "$\\bullet$ The technique of $\\textit{completing the square}$ is about recognizing terms that can be collected into a squared difference expression using,\n",
    "$$ a^2 + b^2 - 2ab = (a-b)^2 $$\n",
    "Look for a similar pattern in the expression.\n",
    "\n",
    "$\\bullet$ If in doubt about $p(x_2)$, try to walk through the exercises again with $x_1$ and $x_2$ switched - would anything change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8010b21c812e41b38dc12f0312004490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, continuous_update=False, description='v', max=5.0, min=-5.0), Floâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def plotCondition(v,cov):    \n",
    "\n",
    "    #define means, variances and covariance matrix\n",
    "    mu_x = 0;\n",
    "    mu_y = 0;\n",
    "\n",
    "    sigma_xx = 1\n",
    "    sigma_yy = 1\n",
    "    sigma_xy = cov\n",
    "    SIGMA = [ [sigma_xx, sigma_xy],[sigma_xy, sigma_yy]]  \n",
    "\n",
    "    #compute correlation coefficient and conditional mean and variance\n",
    "    rho = sigma_xy/np.sqrt(sigma_xx*sigma_yy)\n",
    "    print('correlation coefficient = ',rho)\n",
    "    mu_ = mu_x+rho*(v-mu_y)/sigma_yy\n",
    "    sigma_ = sigma_xx*np.sqrt(1-rho*rho)\n",
    "\n",
    "    #plot contour of p(x,y) and y = v as a line\n",
    "    plt.figure(figsize=(10,10))\n",
    "    x1 = np.linspace(-10,10, 100)\n",
    "    ax1 = plt.subplot(221)\n",
    "    x, y = np.meshgrid(x1,x1)\n",
    "    pos = np.empty(x.shape + (2,))\n",
    "    pos[:, :, 0] = x; pos[:, :, 1] = y\n",
    "    multinorm = multivariate_normal([mu_x, mu_y], SIGMA)\n",
    "    plt.contour(x, y, multinorm.pdf(pos),levels=np.logspace(-10,-1,10), cmap='RdBu_r',norm=colors.LogNorm())\n",
    "    plt.hlines(v, -8,8, colors='k', linestyles='dashed', label = 'y=v')\n",
    "    plt.setp(ax1.get_xticklabels(), visible=False)\n",
    "    plt.ylabel('y')\n",
    "    plt.legend()\n",
    "    plt.axis([-10,10,-10,10])\n",
    "    plt.axis('equal')\n",
    "    plt.grid(True)\n",
    "\n",
    "    #plot the marginal, p(x), and conditional, p(x|y=v) \n",
    "    ax2 = plt.subplot(223)\n",
    "    \n",
    "    h = plt.plot(x1,norm.pdf(x1,mu_,sigma_), label = 'p(x|y=v)')\n",
    "    plt.vlines(mu_,0,norm.pdf(mu_,mu_,sigma_),color=h[0].get_color(),alpha=0.5)\n",
    "    h = plt.plot(x1,norm.pdf(x1,mu_x,sigma_xx), label = 'p(x)');\n",
    "    plt.vlines(mu_x,0,norm.pdf(mu_x,mu_x,sigma_xx),color=h[0].get_color(),alpha=0.5)\n",
    "    \n",
    "    plt.scatter(v,0,color='k',marker='o',label='v',zorder=10,s=80)\n",
    "    plt.ylim(0,0.9)\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('density')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    \n",
    "    ax3 = plt.subplot(222)\n",
    "    covs = np.linspace(-1,1,100)[1:-1]\n",
    "    plt.plot(covs,covs*v)\n",
    "    plt.scatter(cov,cov*v,color='k')\n",
    "    plt.hlines(v,-1,1,color='k',linestyle='--')\n",
    "    plt.xlabel(r'$\\rho$')\n",
    "    plt.ylabel('mean of $p(x|y=v)$')\n",
    "    plt.axis([-1,1,-5,5])\n",
    "    ax4 = plt.subplot(224)\n",
    "    covs = np.linspace(-1,1,100)[1:-1]\n",
    "    plt.plot(covs,np.sqrt(1-np.square(covs)))\n",
    "    plt.scatter(cov,np.sqrt(1-np.square(cov)),color='k')\n",
    "    plt.xlabel(r'${\\rho}$')\n",
    "    plt.ylabel('deviation of $p(x|y=v)$')\n",
    "    plt.axis([-1,1,0,1.1])\n",
    "    \n",
    "interact(plotCondition, \n",
    "    v=FloatSlider(min = -5.0, max = 5.0, value = 0, continuous_update=False),\n",
    "    cov = FloatSlider(min = -.9, max = .9, value = 0, continuous_update = False),\n",
    "\n",
    ");  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
